import json
import os
import shutil
from langchain_core.documents import Document
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings




# --- Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN ---
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_FILE = os.path.join(BASE_DIR, 'data', 'raw', 'products.json')
DB_DIR = os.path.join(BASE_DIR, 'data', 'vector_db')


def load_and_process_data():
    print(f"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u tá»«: {DATA_FILE}")
    if not os.path.exists(DATA_FILE):
        print("âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file dá»¯ liá»‡u. HÃ£y cháº¡y data_crawler.py trÆ°á»›c!")
        return []

    with open(DATA_FILE, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)

    documents = []
    for item in raw_data:
        # 1. Ná»™i dung Ä‘á»ƒ Embed (Vector Search)
        page_content = item.get("rag_content", "")

        # 2. Metadata (Structured Search) - LOGIC Má»šI Cá»¦A Báº N
        url_lower = item.get("url", "").lower()

        # PhÃ¢n loáº¡i dá»±a trÃªn tá»« khÃ³a trong URL
        if any(x in url_lower for x in ['laptop', 'macbook', 'surface', 'matebook']):
            cat = "Laptop"
        elif any(x in url_lower for x in ['iphone', 'samsung', 'xiaomi', 'oppo', 'phone', 'redmi', 'android']):
            cat = "Äiá»‡n thoáº¡i"
        else:
            cat = "Phá»¥ kiá»‡n"

        metadata = {
            "source": item.get("url", "unknown"),
            "name": item.get("name", "unknown"),
            "price": item.get("price_int", 0),
            "category": cat  # DÃ¹ng biáº¿n cat vá»«a tÃ­nh
        }

        # Táº¡o Document
        doc = Document(page_content=page_content, metadata=metadata)
        documents.append(doc)

    print(f"âœ… ÄÃ£ chuáº©n bá»‹ {len(documents)} documents.")
    return documents


def build_db():
    # 1. Load dá»¯ liá»‡u
    docs = load_and_process_data()
    if not docs: return

    # 2. Chunking
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50
    )
    splits = text_splitter.split_documents(docs)
    print(f"âœ‚ï¸ ÄÃ£ chia thÃ nh {len(splits)} chunks nhá».")

    # 3. Khá»Ÿi táº¡o Embedding Model
    print("ğŸ§  Äang táº£i model Embedding (cÃ³ thá»ƒ máº¥t 1-2 phÃºt láº§n Ä‘áº§u)...")
    # ThÃªm show_progress Ä‘á»ƒ báº¡n biáº¿t nÃ³ Ä‘ang táº£i
    embedding_model = HuggingFaceEmbeddings(
        model_name="keepitreal/vietnamese-sbert",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

    # 4. XÃ³a DB cÅ© Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p
    if os.path.exists(DB_DIR):
        try:
            shutil.rmtree(DB_DIR)
            print("ğŸ§¹ ÄÃ£ xÃ³a database cÅ©.")
        except Exception as e:
            print(f"âš ï¸ KhÃ´ng thá»ƒ xÃ³a DB cÅ© (cÃ³ thá»ƒ Ä‘ang má»Ÿ): {e}")

    # 5. Táº¡o Vector DB
    print("ğŸ’¾ Äang táº¡o Vector Database...")
    vector_db = Chroma.from_documents(
        documents=splits,
        embedding=embedding_model,
        persist_directory=DB_DIR
    )

    print(f"ğŸ‰ ThÃ nh cÃ´ng! Database Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {DB_DIR}")

    # --- TEST NHANH ---
    print("\n--- ğŸ•µï¸ TEST THá»¬ KHáº¢ NÄ‚NG TÃŒM KIáº¾M ---")
    query = "MÃ¡y nÃ o chÆ¡i game tá»‘t giÃ¡ ráº»?"
    results = vector_db.similarity_search(query, k=1)
    if results:
        print(f"CÃ¢u há»i: {query}")
        print(f"TÃ¬m tháº¥y SP: {results[0].metadata.get('name')}")
        print(f"Ná»™i dung: {results[0].page_content[:200]}...")
    else:
        print("KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ nÃ o.")


if __name__ == "__main__":
    build_db()