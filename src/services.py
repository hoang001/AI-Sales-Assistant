import urllib.parse
import json
import os
from .database import db_manager
from .config import settings
import unicodedata

# Import Search Engine
try:
    from src.search_engine import StoreSearchEngine
except ImportError:
    StoreSearchEngine = None

class StoreService:
    def __init__(self):
        print("‚è≥ ƒêang t·∫£i RAG Engine...")
        self.rag = StoreSearchEngine() if StoreSearchEngine else None

    def search_products(self, query: str, limit: int = 10):
        """
        T√¨m ki·∫øm s·∫£n ph·∫©m b·∫±ng RAG Vector + SQL.
        Tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng Markdown bao g·ªìm: ·∫¢nh, Gi√°, ƒê√°nh gi√°, Th√¥ng s·ªë.
        """
        if not self.rag: return "H·ªá th·ªëng t√¨m ki·∫øm ƒëang b·∫£o tr√¨."
        
        # 1. T√¨m ki·∫øm Vector (T√¨m theo √Ω hi·ªÉu)
        results = self.rag.search(query, k=limit)
        if not results: return "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o ph√π h·ª£p."
        
        conn = db_manager.get_connection()
        cursor = conn.cursor()
        
        response_text = ""
        print(f"\n--- DEBUG T√åM ·∫¢NH ({len(results)} k·∫øt qu·∫£) ---")
        
        for doc in results:
            name = doc.metadata.get('name')
            
            # [QUAN TR·ªåNG] L·∫•y th√™m c·ªôt 'rag_content' ƒë·ªÉ hi·ªÉn th·ªã th√¥ng s·ªë k·ªπ thu·∫≠t cho Frontend V4
            # D√πng LIKE ƒë·ªÉ t√¨m ki·∫øm linh ho·∫°t h∆°n (tr√°nh l·ªói l·ªách t√™n)
            cursor.execute("SELECT price_int, image_url, discount_rate, rating_avg, review_count, rag_content FROM products WHERE name LIKE ? LIMIT 1", (f"%{name}%",))
            row = cursor.fetchone()
            
            if row:
                original_price, img_url, discount, rating, reviews, specs_text = row
                
                print(f"‚úÖ T√¨m th·∫•y SQL: {name} | ·∫¢nh: {str(img_url)[:30]}...")

                # 1. X·ª≠ l√Ω URL ·∫£nh an to√†n
                if img_url and len(str(img_url)) > 5:
                    img_url = urllib.parse.quote(img_url, safe=":/?#[]@!$&'()*+,;=")
                else:
                    img_url = "https://via.placeholder.com/300x300?text=No+Image"

                # 2. X·ª≠ l√Ω d·ªØ li·ªáu hi·ªÉn th·ªã (Rating, Stars)
                rating = rating if rating else 0
                reviews = reviews if reviews else 0
                star_icon = "‚≠ê" * int(round(rating)) if rating > 0 else ""

                # 3. X·ª≠ l√Ω th√¥ng s·ªë k·ªπ thu·∫≠t (C·∫Øt ng·∫Øn cho g·ªçn ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp tr√™n Card)
                if specs_text:
                    # Lo·∫°i b·ªè ph·∫ßn t√™n l·∫∑p l·∫°i ·ªü ƒë·∫ßu chu·ªói rag_content
                    # V√≠ d·ª•: "S·∫£n ph·∫©m: iPhone 15. C·∫•u h√¨nh:..." -> "C·∫•u h√¨nh:..."
                    short_specs = specs_text.replace(f"S·∫£n ph·∫©m: {name}.", "").strip()
                    # L·∫•y kho·∫£ng 150 k√Ω t·ª± ƒë·∫ßu ti√™n
                    short_specs = short_specs[:160] + "..." if len(short_specs) > 160 else short_specs
                else:
                    short_specs = "ƒêang c·∫≠p nh·∫≠t..."

                # 4. T√≠nh gi√° khuy·∫øn m√£i
                final_price = original_price * (1 - discount/100)
                
                if discount > 0:
                    price_display = f"üî• **{final_price:,.0f}ƒë** (Gi·∫£m {discount}% - G·ªëc: ~{original_price:,.0f}ƒë~)"
                else:
                    price_display = f"üí∞ **{original_price:,.0f}ƒë**"
                
                # 5. T·∫°o Markdown chu·∫©n (Frontend b·∫Øt bu·ªôc ph·∫£i theo format n√†y ƒë·ªÉ render th·∫ª)
                # Format: **T√™n** \n ![·∫¢nh](URL) \n - Gi√° \n - Rating \n - Th√¥ng s·ªë \n - M√¥ t·∫£
                response_text += f"""
**{name}**
![{name}]({img_url})
- {price_display}
- {star_icon} **{rating}/5** ({reviews} ƒë√°nh gi√°)
- ‚öôÔ∏è Th√¥ng s·ªë: {short_specs}
- üìù *{doc.page_content[:100]}...*
---
"""
            else:
                print(f"‚ùå Kh√¥ng t√¨m th·∫•y trong SQL: {name} (S·∫Ω m·∫•t ·∫£nh)")
                # Fallback: Tr·∫£ v·ªÅ th√¥ng tin c∆° b·∫£n t·ª´ Vector DB n·∫øu kh√¥ng kh·ªõp SQL
                price_vec = doc.metadata.get('price', 0)
                response_text += f"- **{name}** (Gi√° tham kh·∫£o: {price_vec:,.0f}ƒë)\n"

        conn.close()
        return response_text

    def check_stock(self, product_name: str):
        """Ki·ªÉm tra t·ªìn kho"""
        conn = db_manager.get_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT name, price_int, stock, discount_rate FROM products WHERE name LIKE ?", (f"%{product_name}%",))
        item = cursor.fetchone()
        conn.close()
        
        if item:
            name, price, stock, discount = item
            final_price = price * (1 - discount/100)
            status = f"‚úÖ C√íN {stock} chi·∫øc" if stock > 0 else "‚ùå H·∫æT H√ÄNG"
            return f"S·∫£n ph·∫©m **{name}**\n- T√¨nh tr·∫°ng: {status}\n- Gi√° hi·ªán t·∫°i: {final_price:,.0f}ƒë (ƒê√£ gi·∫£m {discount}%)"
        return "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†y."

    def remove_accents(self, input_str):
        if not input_str: return ""
        nfkd_form = unicodedata.normalize('NFKD', input_str)
        return "".join([c for c in nfkd_form if not unicodedata.combining(c)])

    def find_stores(self, location: str):
        """T√¨m c·ª≠a h√†ng CellphoneS (Phi√™n b·∫£n ch·∫•p nh·∫≠n kh√¥ng d·∫•u v√† t√¨m ki·∫øm linh ho·∫°t)"""
        import json
        import os
        import time
        
        try:
            base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            store_path = os.path.join(base_dir, 'data', 'raw', 'store.json')
            with open(store_path, 'r', encoding='utf-8') as f:
                all_stores = json.load(f)
        except Exception as e:
            print(f"‚ùå L·ªói ƒë·ªçc file store.json: {e}")
            return "‚ö†Ô∏è H·ªá th·ªëng ƒëang b·∫£o tr√¨ d·ªØ li·ªáu c·ª≠a h√†ng."

        # 1. Chu·∫©n h√≥a t·ª´ kh√≥a t√¨m ki·∫øm (X√≥a d·∫•u, ch·ªØ th∆∞·ªùng, lo·∫°i b·ªè c√°c t·ª´ ch·ªâ ƒë·ªãa danh h√†nh ch√≠nh)
        # V√≠ d·ª•: "Ph∆∞·ªùng Vinh H∆∞ng" -> "vinh hung", "Qu·∫≠n C·∫ßu Gi·∫•y" -> "cau giay"
        loc_norm = self.remove_accents(location.lower())
        # Lo·∫°i b·ªè c√°c t·ª´ ch·ªâ ƒë·ªãa danh h√†nh ch√≠nh
        loc_norm = loc_norm.replace("quan", "").replace("huyen", "").replace("thanh pho", "").replace("tp", "").replace("phuong", "").replace("xa", "").replace("ward", "").replace("district", "").strip()
        # X√≥a c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát v√† kho·∫£ng tr·∫Øng th·ª´a
        loc_norm = " ".join(loc_norm.split())
        
        #region agent log
        with open(r"d:\HOCTAP\KHMT\AI-Sales-Assistant\.cursor\debug.log", "a", encoding="utf-8") as _f:
            _f.write(json.dumps({
                "sessionId": "debug-session",
                "runId": "post-fix",
                "hypothesisId": "H1",
                "location": "services.py:141",
                "message": "find_stores entry",
                "data": {"raw_location": location, "loc_norm": loc_norm},
                "timestamp": int(time.time() * 1000)
            }) + "\n")
        #endregion
        
        if not loc_norm:
            return f"D·∫° em kh√¥ng hi·ªÉu ƒë·ªãa ƒëi·ªÉm '{location}'. Anh/ch·ªã vui l√≤ng nh·∫≠p t√™n Qu·∫≠n/Huy·ªán ho·∫∑c Ph∆∞·ªùng/X√£ c·ª• th·ªÉ h∆°n ·∫°."
        
        found_stores = []
        words = [w for w in loc_norm.split() if len(w) > 1]
        #region agent log
        with open(r"d:\HOCTAP\KHMT\AI-Sales-Assistant\.cursor\debug.log", "a", encoding="utf-8") as _f:
            _f.write(json.dumps({
                "sessionId": "debug-session",
                "runId": "post-fix",
                "hypothesisId": "H4",
                "location": "services.py:159",
                "message": "tokenized_location",
                "data": {"loc_norm": loc_norm, "words": words, "word_count": len(words)},
                "timestamp": int(time.time() * 1000)
            }) + "\n")
        #endregion

        # 2. So s√°nh th√¥ng minh (t√¨m ki·∫øm trong c·∫£ address v√† city)
        for store in all_stores:
            # Chu·∫©n h√≥a ƒë·ªãa ch·ªâ trong DB (x√≥a d·∫•u, ch·ªØ th∆∞·ªùng)
            addr_norm = self.remove_accents(store.get('address', '').lower())
            city_norm = self.remove_accents(store.get('city', '').lower())
            name_norm = self.remove_accents(store.get('name', '').lower())

            matched = False
            match_reason = ""

            # ∆Øu ti√™n kh·ªõp c·ª•m ƒë·∫ßy ƒë·ªß
            if (loc_norm and (loc_norm in addr_norm or loc_norm in city_norm or loc_norm in name_norm)):
                matched = True
                match_reason = "full_loc_norm"
            # N·∫øu c√≥ >=2 t·ª´: y√™u c·∫ßu T·∫§T C·∫¢ t·ª´ ph·∫£i xu·∫•t hi·ªán trong C√ôNG M·ªòT tr∆∞·ªùng (address HO·∫∂C city HO·∫∂C name)
            # QUAN TR·ªåNG: D√πng T·∫§T C·∫¢ t·ª´ (kh√¥ng filter), ƒë·ªÉ tr√°nh m·∫•t t·ª´ ng·∫Øn nh∆∞ "my" trong "my dinh"
            elif len(words) >= 2:
                # Ki·ªÉm tra xem t·∫•t c·∫£ t·ª´ c√≥ xu·∫•t hi·ªán trong c√πng m·ªôt tr∆∞·ªùng kh√¥ng
                if (all(word in addr_norm for word in words) or
                    all(word in city_norm for word in words) or
                    all(word in name_norm for word in words)):
                    matched = True
                    match_reason = "all_words_match_same_field"
            # N·∫øu ch·ªâ 1 t·ª´: y√™u c·∫ßu t·ª´ ƒë·ªß d√†i (>3) v√† xu·∫•t hi·ªán trong ƒë·ªãa ch·ªâ/t√™n/th√†nh ph·ªë
            elif len(words) == 1:
                w = words[0]
                if len(w) > 3 and (w in addr_norm or w in city_norm or w in name_norm):
                    matched = True
                    match_reason = "single_word"

            if matched:
                found_stores.append(store)
                #region agent log
                if len(found_stores) <= 5:
                    with open(r"d:\HOCTAP\KHMT\AI-Sales-Assistant\.cursor\debug.log", "a", encoding="utf-8") as _f:
                        _f.write(json.dumps({
                            "sessionId": "debug-session",
                            "runId": "post-fix",
                            "hypothesisId": "H2",
                            "location": "services.py:204",
                            "message": "match_found",
                            "data": {
                                "loc_norm": loc_norm,
                                "words": words,
                                "word_count": len(words),
                                "matched_store": store.get('name'),
                                "store_address": store.get('address', '')[:60],
                                "store_city": store.get('city', ''),
                                "reason": match_reason,
                                "addr_contains_all_words": all(word in addr_norm for word in words) if len(words) >= 2 else None,
                                "city_contains_all_words": all(word in city_norm for word in words) if len(words) >= 2 else None
                            },
                            "timestamp": int(time.time() * 1000)
                        }) + "\n")
                #endregion
        
        if not found_stores:
            #region agent log
            with open(r"d:\HOCTAP\KHMT\AI-Sales-Assistant\.cursor\debug.log", "a", encoding="utf-8") as _f:
                _f.write(json.dumps({
                    "sessionId": "debug-session",
                    "runId": "post-fix",
                    "hypothesisId": "H3",
                    "location": "services.py:237",
                    "message": "no_store_found",
                    "data": {"loc_norm": loc_norm, "words": words, "word_count": len(words)},
                    "timestamp": int(time.time() * 1000)
                }) + "\n")
            #endregion
            return f"D·∫° em ch∆∞a t√¨m th·∫•y chi nh√°nh ·ªü khu v·ª±c '{location}'. Anh/ch·ªã th·ª≠ nh·∫≠p t√™n Qu·∫≠n/Huy·ªán l·ªõn h∆°n xem sao ·∫°? (V√≠ d·ª•: 'C·∫ßu Gi·∫•y', 'ƒê·ªëng ƒêa', 'Qu·∫≠n 1')"

        display_stores = found_stores[:5]
        response_text = f"üéâ T√¨m th·∫•y **{len(found_stores)}** c·ª≠a h√†ng g·∫ßn **{location}**:\n\n"
        
        for s in display_stores:
            response_text += f"üè† **{s['name']}**\n- üìç {s['address']}\n- üó∫Ô∏è [Xem b·∫£n ƒë·ªì]({s['map_url']})\n---\n"
            
        return response_text

store_service = StoreService()